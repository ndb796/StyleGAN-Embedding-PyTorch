{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Image Alignment",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWWhR+nzwazNEMYQ629vkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndb796/StyleGAN-Embedding-PyTorch/blob/main/Face_Image_Alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJGZfGf3NN-u"
      },
      "source": [
        "### <b>Load Dataset</b>\r\n",
        "\r\n",
        "* <b>Image directory path</b>: *aligned_images*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHXkD24ANNjZ",
        "outputId": "e298ec3f-cf12-4f6f-f620-7edbffaa24c9"
      },
      "source": [
        "!git clone https://github.com/ndb796/StyleGAN-Embedding-PyTorch\r\n",
        "%cd StyleGAN-Embedding-PyTorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'StyleGAN-Embedding-PyTorch'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 22 (delta 1), reused 16 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n",
            "/content/StyleGAN-Embedding-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEDlcbcOFMny"
      },
      "source": [
        "### <b>Define Image Alignment Library</b>\r\n",
        "\r\n",
        "* Reference: https://github.com/Puzer/stylegan-encoder/blob/master/align_images.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuy-B5kEGiK"
      },
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import scipy.ndimage\r\n",
        "import PIL.Image\r\n",
        "\r\n",
        "import dlib\r\n",
        "import bz2\r\n",
        "\r\n",
        "from keras.utils import get_file\r\n",
        "\r\n",
        "\r\n",
        "def image_align(src_file, dst_file, face_landmarks, output_size=1024, transform_size=4096, enable_padding=True):\r\n",
        "        # Align function from FFHQ dataset pre-processing step\r\n",
        "        # https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py\r\n",
        "\r\n",
        "        lm = np.array(face_landmarks)\r\n",
        "        lm_chin          = lm[0  : 17]  # left-right\r\n",
        "        lm_eyebrow_left  = lm[17 : 22]  # left-right\r\n",
        "        lm_eyebrow_right = lm[22 : 27]  # left-right\r\n",
        "        lm_nose          = lm[27 : 31]  # top-down\r\n",
        "        lm_nostrils      = lm[31 : 36]  # top-down\r\n",
        "        lm_eye_left      = lm[36 : 42]  # left-clockwise\r\n",
        "        lm_eye_right     = lm[42 : 48]  # left-clockwise\r\n",
        "        lm_mouth_outer   = lm[48 : 60]  # left-clockwise\r\n",
        "        lm_mouth_inner   = lm[60 : 68]  # left-clockwise\r\n",
        "\r\n",
        "        # Calculate auxiliary vectors.\r\n",
        "        eye_left     = np.mean(lm_eye_left, axis=0)\r\n",
        "        eye_right    = np.mean(lm_eye_right, axis=0)\r\n",
        "        eye_avg      = (eye_left + eye_right) * 0.5\r\n",
        "        eye_to_eye   = eye_right - eye_left\r\n",
        "        mouth_left   = lm_mouth_outer[0]\r\n",
        "        mouth_right  = lm_mouth_outer[6]\r\n",
        "        mouth_avg    = (mouth_left + mouth_right) * 0.5\r\n",
        "        eye_to_mouth = mouth_avg - eye_avg\r\n",
        "\r\n",
        "        # Choose oriented crop rectangle.\r\n",
        "        x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\r\n",
        "        x /= np.hypot(*x)\r\n",
        "        x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\r\n",
        "        y = np.flipud(x) * [-1, 1]\r\n",
        "        c = eye_avg + eye_to_mouth * 0.1\r\n",
        "        quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\r\n",
        "        qsize = np.hypot(*x) * 2\r\n",
        "\r\n",
        "        # Load in-the-wild image.\r\n",
        "        if not os.path.isfile(src_file):\r\n",
        "            print('\\nCannot find source image. Please run \"--wilds\" before \"--align\".')\r\n",
        "            return\r\n",
        "        img = PIL.Image.open(src_file)\r\n",
        "\r\n",
        "        # Shrink.\r\n",
        "        shrink = int(np.floor(qsize / output_size * 0.5))\r\n",
        "        if shrink > 1:\r\n",
        "            rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\r\n",
        "            img = img.resize(rsize, PIL.Image.ANTIALIAS)\r\n",
        "            quad /= shrink\r\n",
        "            qsize /= shrink\r\n",
        "\r\n",
        "        # Crop.\r\n",
        "        border = max(int(np.rint(qsize * 0.1)), 3)\r\n",
        "        crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\r\n",
        "        crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\r\n",
        "        if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\r\n",
        "            img = img.crop(crop)\r\n",
        "            quad -= crop[0:2]\r\n",
        "\r\n",
        "        # Pad.\r\n",
        "        pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\r\n",
        "        pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\r\n",
        "        if enable_padding and max(pad) > border - 4:\r\n",
        "            pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\r\n",
        "            img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\r\n",
        "            h, w, _ = img.shape\r\n",
        "            y, x, _ = np.ogrid[:h, :w, :1]\r\n",
        "            mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3]))\r\n",
        "            blur = qsize * 0.02\r\n",
        "            img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\r\n",
        "            img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\r\n",
        "            img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\r\n",
        "            quad += pad[:2]\r\n",
        "\r\n",
        "        # Transform.\r\n",
        "        img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\r\n",
        "        if output_size < transform_size:\r\n",
        "            img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\r\n",
        "\r\n",
        "        # Save aligned image.\r\n",
        "        img.save(dst_file, 'PNG')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uhytdg7EKv6"
      },
      "source": [
        "class LandmarksDetector:\r\n",
        "    def __init__(self, predictor_model_path):\r\n",
        "        \"\"\"\r\n",
        "        :param predictor_model_path: path to shape_predictor_68_face_landmarks.dat file\r\n",
        "        \"\"\"\r\n",
        "        self.detector = dlib.get_frontal_face_detector() # cnn_face_detection_model_v1 also can be used\r\n",
        "        self.shape_predictor = dlib.shape_predictor(predictor_model_path)\r\n",
        "\r\n",
        "    def get_landmarks(self, image):\r\n",
        "        img = dlib.load_rgb_image(image)\r\n",
        "        dets = self.detector(img, 1)\r\n",
        "\r\n",
        "        for detection in dets:\r\n",
        "            face_landmarks = [(item.x, item.y) for item in self.shape_predictor(img, detection).parts()]\r\n",
        "            yield face_landmarks"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZxx9Fa1AOOK"
      },
      "source": [
        "def unpack_bz2(src_path):\r\n",
        "    data = bz2.BZ2File(src_path).read()\r\n",
        "    dst_path = src_path[:-4]\r\n",
        "    with open(dst_path, 'wb') as fp:\r\n",
        "        fp.write(data)\r\n",
        "    return dst_path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-j-59NNuh1"
      },
      "source": [
        "### <b>Image Alignment</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Q3-LglD29l"
      },
      "source": [
        "\"\"\"\r\n",
        "Extracts and aligns all faces from images using DLib and a function from original FFHQ dataset preparation step\r\n",
        "python align_images.py /raw_images /aligned_images\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "LANDMARKS_MODEL_URL = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\r\n",
        "landmarks_model_path = unpack_bz2(get_file('shape_predictor_68_face_landmarks.dat.bz2', LANDMARKS_MODEL_URL, cache_subdir='temp'))\r\n",
        "\r\n",
        "RAW_IMAGES_DIR = './raw_images'\r\n",
        "ALIGNED_IMAGES_DIR = './aligned_images'\r\n",
        "\r\n",
        "if not os.path.exists(ALIGNED_IMAGES_DIR):\r\n",
        "    os.makedirs(ALIGNED_IMAGES_DIR)\r\n",
        "\r\n",
        "landmarks_detector = LandmarksDetector(landmarks_model_path)\r\n",
        "for img_name in os.listdir(RAW_IMAGES_DIR):\r\n",
        "    raw_img_path = os.path.join(RAW_IMAGES_DIR, img_name)\r\n",
        "    for i, face_landmarks in enumerate(landmarks_detector.get_landmarks(raw_img_path), start=1):\r\n",
        "        face_img_name = '%s_%02d.png' % (os.path.splitext(img_name)[0], i)\r\n",
        "        aligned_face_path = os.path.join(ALIGNED_IMAGES_DIR, face_img_name)\r\n",
        "\r\n",
        "        image_align(raw_img_path, aligned_face_path, face_landmarks)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuzVCSFNPQMM"
      },
      "source": [
        "### <b>Save Aligned Images</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBtIN-HPTR9",
        "outputId": "80b3e227-b463-4f02-cbb9-0282046f5890"
      },
      "source": [
        "!zip aligned_images ./aligned_images/*"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: aligned_images/amanda_seyfried_01.png (deflated 0%)\n",
            "  adding: aligned_images/anne_hathaway_01.png (deflated 0%)\n",
            "  adding: aligned_images/barack_obama_01.png (deflated 0%)\n",
            "  adding: aligned_images/donald_trump_01.png (deflated 0%)\n",
            "  adding: aligned_images/emma_stone_01.png (deflated 0%)\n",
            "  adding: aligned_images/hugh_jackman_01.png (deflated 0%)\n",
            "  adding: aligned_images/keanu_reeves_01.png (deflated 0%)\n",
            "  adding: aligned_images/natalie_portman_01.png (deflated 0%)\n",
            "  adding: aligned_images/scarlett_johansson_01.png (deflated 0%)\n",
            "  adding: aligned_images/tom_hardy_01.png (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}